<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8"/>
    <title>Docker</title>
    <link href="/study/index.css" rel="stylesheet"/>
  </head>
  <body>
    <h1>Docker</h1>
    <ul>
      <li><a href="https://gist.github.com/ju2wheels/3d1a1dfa498977874d03">Docker file reference</a></li>
      <li><a href="http://stackoverflow.com/questions/27912917/how-to-configure-docker-port-mapping-to-use-nginx-as-an-upstream-proxy">Docker ports served via nginx</a></li>
      <li><a href="http://stackoverflow.com/questions/22111060/difference-between-expose-and-publish-in-docker">Difference between expose and publish</a> [Basically expose is for inter container communication where as publish allows for communication outside docker containers]</li>
      <li><a href="http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/">Automated nginx reverse proxy for docker</a></li>
      <li><a href="http://stackoverflow.com/questions/26153686/how-to-run-a-command-on-an-already-existing-docker-container">Running Command on an existing docker container</a></li>
      <li><a href="http://stackoverflow.com/questions/24706708/how-to-start-docker-container-as-server">Running docker container as a server</a></li>
      <li id="events"><a href="https://docs.docker.com/engine/reference/commandline/events/">A guide to docker events</a> [Docker events can be formatted as json and handled by any program that can read the output from the shell]</li>
      <li><a href="https://docs.docker.com/engine/api/v1.26/">It seems that docker has an http api</a> [Oh yes baby]</li>
      <li><a href="http://stackoverflow.com/questions/24702233/docker-container-and-memory-consumption">The memory consumption of a docker container</a></li>
      <li><a href="http://stackoverflow.com/documentation/docker/3935/docker-remote-api#t=201703080728266851921">Enable remote api for docker</a></li>
      <li><a href="http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker">Persistent storage in docker</a></li>
      <li><a href="https://github.com/tianon/dockerfiles">Big list of dockerfiles</a> [Can help in understanding various commands]</li>
      <li><a href="https://groups.google.com/forum/#!topic/docker-user/RDpH2OYs6Xw">Docker images don't need to contain an os</a></li>
      <li>Docker files can be <a href="https://github.com/docker/docker/issues/3378">chained</a>. [We'll probably have to use this technique to configure our node and redis environments before launching nodebb it seems]</li>
      <li>Every instruction is a layer in a docker image. Which ties well with docker's  <a href="#prop_changes"> change propagation mechanism</a>. </li>
    </ul>
    <h1>Things that we need to do with docker</h1>
    <ol>        
      <li>Perform housekeeping tasks-- dynamically replace the files in the <em>/install/data/</em> directory depending upon <a href="/study/forums.html#stat_data">the type of forum</a> software that we want to create.</li>
      <li>Auto install nodebb with all of it's dependencies in separate (individual) containers -- imagemagick, node, node_modules,redis and nodebb <a href="/study/forums.html#plug_list">plugins</a>.</li>
      <li>The status of installation should be <a href="#events">notified</a> to the process that initiated the installation.</li>
      <li>Configure docker in a way that we are able to <a href="#alter_exec">send commands</a> to it during run time.</li>
    </ol>
    <h1>Notes</h1>
    <p id="prop_changes"><em>"When you change a Docker image, such as when you update an application to a new version, a new layer is built and replaces only the layer it updates. The other layers remain intact. To distribute the update, you only need to transfer the updated layer. Layering speeds up distribution of Docker images. Docker determines which layers need to be updated at runtime."</em>-- <s>This means that we should be able to install plugins and update dependencies on a single docker image and the changes will propagate to all the containers. [Man this is getting better and better]</s> [It seems that the layering only applied to image builds and does not actually propagate to containers. But we have a <a href="#alter_exec">few alternatives</a>]</p>
    <p id="alter_exec">There is an api endpoint that <a href="https://docs.docker.com/engine/api/v1.26/#operation/ContainerExec">creates exec instances</a>. Although we can run command inside a docker container using this api we won't need to do so. Since the docker containers will be networked we can simply instruct them to run a <a href="#prop_updates">command via http</a>. </p>

    <p><em>"Not at all! Any data that your application writes to disk gets preserved in its container until you explicitly delete the container. The file system for the container persists even after the container halts."</em>[It seems that data does persist inside the <a href="#ex_im">docker container</a>]</p>
    <p id="ex_im">Docker containers can be compressed into a tar file and then exported, later on the data from the tar file can be imported in a different container. So that whatever data is stored inside the UFS is safe as long as the container is not deleted. [Forget about all the best practices of having a volume seperate from the data and other mumbo jumbo]. This answer gives the details of some alternative <a href="http://stackoverflow.com/questions/26331651/how-can-i-backup-a-docker-container-with-its-data-volumes">data backup</a> strategies.</p>
    <p id="h_name">Docker allows us to <a href="https://docs.docker.com/engine/api/v1.26/#operation/ContainerCreate">set hostnames</a> that can be used to access containers. These hostnames can be randomly generated ids stored in a database  proxied by a master nginx server.</p>
    <p>Docker runs as root by default.</p>
    <p>We can run docker images either <a href="http://stackoverflow.com/questions/18497688/run-a-docker-image-as-a-container">by name or by ids</a>. The advantage of using id is that we won't have to waste any time in laying down a naming convention for our images. The disadvantage is that the id of the image does not give us much hint of what the image actually contains. But the disadvantage is bearable. We won't be changing images. We'll make containers smart instead.</p>
    <p><strong>Propagating updates to docker containers via a git branch</strong></p>
    <div id="prop_updates">
      The problem of propagating updates to the containers can be easily solved by pulling the changes from a git branch. We need to create a base image that initializes a container and the applications in it with to a default state. The actual state of the application would be maintained inside a git repository. Once we push updates to the repo we can instruct the master process to command a container to pull all the updates from the repo and restart the applications. This would work because:-
      <ol>
          <li>The containers are networked</li>
          <li>The master process has the ids of all the containers in a network</li>
      </ol>
      Later on when the update has been applied to the container and the application server has been restarted we can send a notification to the master process. In openresty terms this simply translates to a handler on the master server that listens to the incoming post requests.
    </div>
    <p><small>-- <a href="/about.html">Akshat Jiwan Sharma</a></small></p>     

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-37138783-1']);
      _gaq.push(['_trackPageview']);

      (function ()
      {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    <script src="/jquery-1.11.1.min.js" type="text/javascript"></script>
    <script src="/study/index.js" type="text/javascript"></script>

  </body>
</html>
